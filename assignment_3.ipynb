{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6c1330",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "### Due 9/23. Do four of five."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7761202",
   "metadata": {},
   "source": [
    "1. \n",
    "- Open the NHANES (or Ames prices or college completion datasets, if you prefer)\n",
    "- Find two categorical variables of interest (there are 198, and short descriptions are given in the `nhanes_meta_17_18.csv` file). Investigate their missing values (you don't have to focus on missing values for this analysis like we did with police use of force, but always be aware of how dirty the data are)\n",
    "- Compute a contingency table for your categorical $X$ and $Y$\n",
    "- Discuss any interesting patterns (or lack of one) that you observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fd8d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95cd4793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jt/l8_nr7mx5jnc_xwsnkl6d_q80000gn/T/ipykernel_11612/3130021996.py:1: DtypeWarning: Columns (142) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nhanes = pd.read_csv('data/nhanes_data_17_18.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>TriedToLoseWeightInPastYear</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TriedToQuitSmoking</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>331</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>292</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "TriedToLoseWeightInPastYear  0.0  1.0\n",
       "TriedToQuitSmoking                   \n",
       "0.0                          331   85\n",
       "1.0                          292  144"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhanes = pd.read_csv('data/nhanes_data_17_18.csv')\n",
    "pd.crosstab(nhanes['TriedToQuitSmoking'], nhanes['TriedToLoseWeightInPastYear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cef48e5",
   "metadata": {},
   "source": [
    "2. \n",
    "- Open the NHANES dataset\n",
    "- Find a categorical and numeric variable of interest (there are 198, and short descriptions are given in the `nhanes_meta_17_18.csv` file). Investigate their missing values (you don't have to focus on missing values for this analysis, but always be aware of them)\n",
    "- Make descriptive tables and grouped kernel density plots to represent the variation in your numeric $Y$ conditional on your categorical $X$\n",
    "- Discuss any interesting patterns (or lack of one) that you observe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4952e789",
   "metadata": {},
   "source": [
    "3. \n",
    "We showed that the mean and median could be discovered by minimizing various kinds of loss functions; this is what machine learning is. To make a prediction $\\hat{y}(z)$ of $Y$ when $X=z$, minimize the mean squared error:\n",
    "$$\n",
    "MSE(\\hat{y}(z)) = \\dfrac{1}{N} \\sum_{i=1}^N \\left\\lbrace y_i - \\hat{y}(z) \\right\\rbrace^2 \\frac{1}{h}k\\left(\\frac{z-x_i}{h}\\right)\n",
    "$$\n",
    "Show that the solution to this problem is the LCLS/Naradaya-Watson estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98884d76",
   "metadata": {},
   "source": [
    "4. \n",
    "- Write a class or set of functions that implement the LCLS/Naradaya-Watson estimator, using the Silverman plug-in estimate for the conditioning variable $X$ as the bandwidth.\n",
    "- From one of the course data sets, find two numeric variables of interest, analyze their relationship with the the LCLS/Naradaya-Watson estimator, and discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534c110",
   "metadata": {},
   "source": [
    "5. \n",
    "- In any of the available data sets, investigate the relationships between pairs of variables $(X,Y)$ with a scatterplot and CEF (for example, price on area)\n",
    "- Is this relationship plausibly causal, or are there missing variables that might explain at least part of the relationship between your variables? These can be \"conceptual\" rather than \"practical\"; for example, 'talent' or 'grit' probably explain education outcomes, but are almost impossible to measure. We are asking whether there are hypothetical **threats to causal identification** of the effect of $X$ on $Y$.\n",
    "- Explain how, regardless of the threat to causal identification, you can still use your model to predict $Y$ given $X$, as long as you don't intervene in the system to control the outcome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds5030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
